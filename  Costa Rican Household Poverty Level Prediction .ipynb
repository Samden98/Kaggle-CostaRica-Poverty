{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "09bd18935de430d820d484abf12914fbeb218b0b"
   },
   "source": [
    "# Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e40825e53e1b3e09d89c890b75ef638e2024ec16"
   },
   "source": [
    "The data for this competition is provided in two files: train.csv and test.csv. The training set has 9557 rows and 143 columns while the testing set has 23856 rows and 142 columns. Each row represents one individual and each column is a feature, either unique to the individual, or for the household of the individual. The training set has one additional column, Target, which represents the poverty level on a 1-4 scale and is the label for the competition. A value of 1 is the most extreme poverty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ce174d384afc979ffd31f57a471b515dffecb522"
   },
   "source": [
    "This is a supervised multi-class classification machine learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7f806f0f36e08eb88fafe72669ee195d6e5393f"
   },
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d3fecd865e496e60a03c83b85d7460c349fc122e"
   },
   "source": [
    "The objective is to predict poverty on a household level i.e the Target Variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5d74e0401952870318509cc8abadc0640486a0de"
   },
   "source": [
    "The core Data Fields are as follows:\n",
    "* Id - a unique identifier for each row.<br>\n",
    "* Target - the target is an ordinal variable indicating groups of income levels.<br>\n",
    "    * 1 = extreme poverty <br>\n",
    "    * 2 = moderate poverty <br>\n",
    "    * 3 = vulnerable households <br> \n",
    "    * 4 = non vulnerable households <br>\n",
    "* idhogar - this is a unique identifier for each household. This can be used to create household-wide features, etc. All rows in a given household will have a matching value for this identifier.<br>\n",
    "* parentesco1 - indicates if this person is the head of the household.<br>\n",
    "* This data contains 142 total columns.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "297a80bced0aafd63f55cb4ca47f49813c315590"
   },
   "source": [
    "As how the norm goes we will be training our data on the train dataset and test our model against the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c91ce114f873d5aa2aa88f83eb126c573fedbc6"
   },
   "source": [
    "# Part I : Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5ab712994096971f1c0612bc616a7687f587bc2"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fdf688af715be3a6fdf5b9c71adde3dba0f191d4"
   },
   "outputs": [],
   "source": [
    "#Data Visualization\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "317ee137c0a968b8b4b5d1b77a9f1104ed60664d"
   },
   "outputs": [],
   "source": [
    "#Loading Data\n",
    "train= pd.read_csv(\"../input/train.csv\")\n",
    "test= pd.read_csv(\"../input/test.csv\")\n",
    "#Displaying the first five rows of the dataset\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e32b587c3488869464eb606be4317637bfe371c3"
   },
   "source": [
    "That gives us a look at all of the columns which don't appear to be in any order. To get a quick overview of the data we use  .info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "acc0a8a3411532783b517dd0c74dd013d095828f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "sns.boxplot(x = 'Target', y = '', data = final);\n",
    "plt.xticks([0, 1, 2, 3], poverty_mapping.values())\n",
    "plt.title('Average Schooling by Target');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "95d7410e66237da21ffe671d1d020a81f2e9d71f"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f9fb2612ba1ed713fe57120f546db2f0b37e4e22"
   },
   "source": [
    "This gives us the no of rows and columns as well as the data types present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a89636d0a444d36ee2a008a298fb2e00c1badd7"
   },
   "source": [
    "To check the count based on groups of income levels from the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4495d3fb24d0861e3f197ffb7542afebff4f14d7"
   },
   "outputs": [],
   "source": [
    "train['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e38c06005489d37aa7ddc7790aff5495fad4ef7"
   },
   "outputs": [],
   "source": [
    "#Visualization based on the above values\n",
    "sns.countplot('Target',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8ba3a1234af0c115eee2026986536ba5e9aea1a"
   },
   "source": [
    "This gives us the statistical summary of the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7b0d7742af061805e04909a0b84f3f8a5994e12"
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "312e077318dbdcf3dc4a8ddca7d54c988388f584"
   },
   "source": [
    "Now we perform the same for the train as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "622414000d2b59e2555f5a07bc51ee2d83ae8aff"
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cc513e9486f47d169e63768523f4e0cea6df87fa"
   },
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c5015ab95b78f6e5baafbb8d9ed05277e2cb9b24"
   },
   "source": [
    "As you can tell we have one column less than the training dataset. This is because of the absence of the 'Target' column which is what we are gonna be predicting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ada41d7b801ca21c049b0dfde9dfc243ec701d7f"
   },
   "source": [
    "Now we are gonna combine the test and train dataset as this way we can reduce the redundancy of performing the same operations of the train on the test dataset. We will separate them after we clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f2b6eedb8799c32631181a04c02340026b2dd750"
   },
   "outputs": [],
   "source": [
    "#We are doing this because the test doesn't have the Target column.\n",
    "train2=train.drop('Target',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9155bcf5e367bfa0e2589fda9c0ae9d26c95ee82"
   },
   "outputs": [],
   "source": [
    "# Appending the data\n",
    "data = train2.append(test,sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c3ce0496a7af60d3b784e9e6d9a2f412bfc856db"
   },
   "source": [
    "Let's have a look at the dependancy rate column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3d75eed80abccf235faadd53e9b03fa93e0d0ca"
   },
   "outputs": [],
   "source": [
    "data['dependency'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "110ee45875610b48216962fcde793cdf1d6cdfc2"
   },
   "source": [
    "1. From the above information we can see that the dependancy column has yes and no values.  For this we map the 1's to yes and 0's to no. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ed0abc0407e19aeaa018f25e66f684b0200e4656"
   },
   "outputs": [],
   "source": [
    "mapping = {\"yes\": 1, \"no\": 0}\n",
    "\n",
    "# Fill in the values with the correct mapping\n",
    "data['dependency'] = data['dependency'].replace(mapping).astype(np.float64)\n",
    "data['edjefa'] = data['edjefa'].replace(mapping).astype(np.float64)\n",
    "data['edjefe'] = data['edjefe'].replace(mapping).astype(np.float64)\n",
    "\n",
    "data[['dependency', 'edjefa', 'edjefe']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "29a5236d45fe27ad71c50928ebd9fb0f61e9d8bd"
   },
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb3642d69b480a135197df164036aa726d69556f"
   },
   "source": [
    "Outliers are the values which are really from the distribution of the data. We have to remove these outliers as they affect our Model. There is only one outlier in this data i.e on the rez_esc column and acorrding to the answer from competition host(https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403), we can safely change the value to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "edf12712670ce6752dc89956af4c5ee62a4df19d"
   },
   "outputs": [],
   "source": [
    "#outlier in test set which rez_esc is 99.0\n",
    "data.loc[data['rez_esc'] == 99.0 , 'rez_esc'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab26e8d71cf906e6790f8bb273a7037abbdb139c"
   },
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2ec502570b492ec7dea69d690d52a8de91fcf8bf"
   },
   "source": [
    "One of the most basic yet important step in EDA is to find the missing values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d525f961ca9f498274662ba54ca1db93af0a2f5b"
   },
   "outputs": [],
   "source": [
    "# Number of missing in each column\n",
    "missing = pd.DataFrame(data.isnull().sum()).rename(columns = {0: 'total'})\n",
    "\n",
    "# Create a percentage missing\n",
    "missing['percent'] = missing['total'] / len(data)\n",
    "\n",
    "missing.sort_values('percent', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c9242d53ef9156b27382f336eafb38184c998fa5"
   },
   "source": [
    "The above value displays all the missing values in the data. Now we need to fill this with appopriate values that are derived from a concrete hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e777db671ff4fc569c1e4f8ba67db6cf1edc631a"
   },
   "outputs": [],
   "source": [
    "data['v18q1'] = data['v18q1'].fillna(0)\n",
    "\n",
    "data.loc[(data['tipovivi1'] == 1), 'v2a1'] = 0\n",
    "data['v2a1-missing'] = data['v2a1'].isnull()\n",
    "\n",
    "data.loc[((data['age'] > 19) | (data['age'] < 7)) & (data['rez_esc'].isnull()), 'rez_esc'] = 0\n",
    "data['rez_esc-missing'] = data['rez_esc'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b3d5f60de850f22b8c88276d53083eb9363abc3"
   },
   "outputs": [],
   "source": [
    "#electricity columns\n",
    "elec = []\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    if row['noelec'] == 1:\n",
    "        elec.append(0)\n",
    "    elif row['coopele'] == 1:\n",
    "        elec.append(1)\n",
    "    elif row['public'] == 1:\n",
    "        elec.append(2)\n",
    "    elif row['planpri'] == 1:\n",
    "        elec.append(3)\n",
    "    else:\n",
    "        elec.append(np.nan)\n",
    "        \n",
    "data['elec'] = elec\n",
    "data['elec-missing'] = data['elec'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "740d7f566c28e5aef6d02156dd49d5cee7719d26"
   },
   "outputs": [],
   "source": [
    "#remove already present electricity columns\n",
    "data = data.drop(columns = ['noelec', 'coopele', 'public', 'planpri'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a139ff734d3a85e01a5d3cfa2237f59a0149736"
   },
   "outputs": [],
   "source": [
    "#walls ordinal\n",
    "data['walls'] = np.argmax(np.array(data[['epared1', 'epared2', 'epared3']]),\n",
    "                           axis = 1)\n",
    "data = data.drop(columns = ['epared1', 'epared2', 'epared3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e885d34293e4abb08dbb7a5749895d6f8b9557ee"
   },
   "outputs": [],
   "source": [
    "#roof ordinal\n",
    "data['roof'] = np.argmax(np.array(data[['etecho1', 'etecho2', 'etecho3']]),\n",
    "                           axis = 1)\n",
    "data = data.drop(columns = ['etecho1', 'etecho2', 'etecho3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eda13b8078b78345bd42f1eac411baa404ea6ab7"
   },
   "outputs": [],
   "source": [
    "#floor ordinal\n",
    "data['floor'] = np.argmax(np.array(data[['eviv1', 'eviv2', 'eviv3']]),\n",
    "                           axis = 1)\n",
    "data = data.drop(columns = ['eviv1', 'eviv2', 'eviv3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f4527f8c6e275a1200cc5792ca93434978f53a18"
   },
   "outputs": [],
   "source": [
    "#Flushing system\n",
    "data['flush'] = np.argmax(np.array(data[[\"sanitario1\",'sanitario5', 'sanitario2', 'sanitario3',\"sanitario6\"]]),\n",
    "                           axis = 1)\n",
    "data = data.drop(columns = [\"sanitario1\",'sanitario5', 'sanitario2', 'sanitario3',\"sanitario6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e66579579099d5e6d3a1ee86cda2dc5441e59e66"
   },
   "outputs": [],
   "source": [
    "#Drop columns with squared variables\n",
    "data = data[[x for x in data if not x.startswith('SQB')]]\n",
    "data = data.drop(columns = ['agesq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4cede9fb256f751c67c6be9a0faccb703cf8d0a3"
   },
   "outputs": [],
   "source": [
    "#waterprovision\n",
    "data['waterprovision'] = np.argmax(np.array(data[['abastaguano', 'abastaguafuera', 'abastaguadentro']]),\n",
    "                           axis = 1)\n",
    "data = data.drop(columns = ['abastaguano', 'abastaguafuera', 'abastaguadentro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "425e46f956e85c35c9525f5d1e0795e4d850f911"
   },
   "outputs": [],
   "source": [
    "#Education Level\n",
    "data['inst'] = np.argmax(np.array(data[[c for c in data if c.startswith('instl')]]), axis = 1)\n",
    "data = data.drop(columns = [c for c in data if c.startswith('instlevel')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37531f4f4261e52cc2098fd1d45e6fe25b1db48c"
   },
   "outputs": [],
   "source": [
    "#cooking\n",
    "data['waterprovision'] = np.argmax(np.array(data[['energcocinar1','energcocinar4', 'energcocinar3', 'energcocinar2']]),\n",
    "                           axis = 1)\n",
    "data = data.drop(columns = ['energcocinar1','energcocinar4', 'energcocinar3', 'energcocinar2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5f656bcefe16f839207abb760908e211e21408c"
   },
   "outputs": [],
   "source": [
    "#meaneduc is defined as average years of education for adults (18+)\n",
    "data.loc[pd.isnull(data['meaneduc']), 'meaneduc'] = data.loc[pd.isnull(data['meaneduc']), 'escolari']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "df38781ba49faa73d3dbddfd0799cb1c6a5feb47"
   },
   "source": [
    "Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e8dcbea28131317d8cff99816380998eb1f91e74"
   },
   "outputs": [],
   "source": [
    "train2=data.iloc[0:9557,:]\n",
    "test2=data.iloc[9557:33413,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db90820e41285457bb787544893ff9f83c9b6639"
   },
   "outputs": [],
   "source": [
    "test2.drop(['Id','idhogar'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f069351dfc356396e62d83e9281d5d1a3cb3c0ae"
   },
   "source": [
    "Assigning the X which are the features and y which is our Target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37c0c13fe89836712cd1b90b1403a2c562575306"
   },
   "outputs": [],
   "source": [
    "X=train2.drop(['Id','idhogar'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a70e950c752891ff106a1e7b32d0e5cba72eb4d"
   },
   "outputs": [],
   "source": [
    "y=train['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "164590a136e785334c3b9c9be3e11dfc62369ed6"
   },
   "source": [
    "# Modeling with XGboost and LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4a0e28c1f09d8e8cf2506949865d5f17aa2bd9eb"
   },
   "source": [
    "Here we are gonna use the two best classification models but for the final submission we will use LightGBM as it produces a better score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "364769810b7ff7cd1bec487465be912d472be184"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a73ca9ee8388481723143c9f22df09f6c4baace"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb # Importing XGboost Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d215e7db1e96d6a1e69f5ce432debb40d36e2a3a"
   },
   "outputs": [],
   "source": [
    "xg=xgb.XGBClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7eb83aeb1408438bfe3baee7d9a9a3894e862383"
   },
   "outputs": [],
   "source": [
    "xg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "97b53f9f524df4abc0194071dc1959e97d62619c"
   },
   "outputs": [],
   "source": [
    "preds = xg.predict(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "418af055e5e3f74d81a4ff045f14b82774c739fa"
   },
   "source": [
    "Custom Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "07f735358a466d4c9694b6ffb14036e59f3ce25a"
   },
   "outputs": [],
   "source": [
    "def macro_f1_score(\n",
    "    \n",
    "    \n",
    "    labels, predictions):\n",
    "    # Reshape the predictions as needed\n",
    "    predictions = predictions.reshape(len(np.unique(labels)), -1 ).argmax(axis = 0)\n",
    "    \n",
    "    metric_value = f1_score(labels, predictions, average = 'macro')\n",
    "    \n",
    "    # Return is name, value, is_higher_better\n",
    "    return 'macro_f1', metric_value, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad92372ecb30a9038aec042b9f75310cae4af38d"
   },
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "720e78c021b1382632849105a44d21ab7ff5a2ba"
   },
   "outputs": [],
   "source": [
    "# Libraries for LightGBM\n",
    "import lightgbm as lgb\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e11c391568fc03613dbd045ce36f169869b77857"
   },
   "outputs": [],
   "source": [
    "lgmodel = lgb.LGBMClassifier(metric = \"\",num_class = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d1772e70d99e51640f769037a72ccd011532271d"
   },
   "outputs": [],
   "source": [
    " hyp_OPTaaS = { 'boosting_type': 'dart',\n",
    "              'colsample_bytree': 0.9843467236959204,\n",
    "              'learning_rate': 0.11598629586769524,\n",
    "              'min_child_samples': 44,\n",
    "              'num_leaves': 49,\n",
    "              'reg_alpha': 0.35397370408131534,\n",
    "              'reg_lambda': 0.5904910774606467,\n",
    "              'subsample': 0.6299872254632797,\n",
    "              'subsample_for_bin': 60611}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "055d18de3a1c2698e736bfa6ba12251b4a7a81b6"
   },
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(**hyp_OPTaaS, class_weight = 'balanced',max_depth=-1,objective = 'multiclass', n_jobs = -1, n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b83dbcd94b1ac9717e626c1ee5c01de3a0280c1"
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "786ba172b32644af9b54320a0cb89340f2bd5c1e"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa74f71775210940ff1dce31c51884d81a473b0b"
   },
   "outputs": [],
   "source": [
    "pred=model.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bc7955dc05d0b11dd360edd0d5a7a9d56b07b465"
   },
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'Id': test.Id, 'Target': pred})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
